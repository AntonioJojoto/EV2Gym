{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31970b21-beaf-4d3f-961d-0d03881b22df",
   "metadata": {},
   "source": [
    "## Script to generate graphs from agents\n",
    "\n",
    "This script first runs one episode using ChargeAsFastAsPossible agent and saves the replay, then the other agents use the same trayectory. \n",
    "\n",
    "### First, declare the env and set the names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3eb9e32-6374-48a8-82c0-b0ba71dc2aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24277/4192108037.py:4: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
      "  import pkg_resources\n",
      "/tmp/ipykernel_24277/4192108037.py:16: DeprecationWarning: Use of .. or absolute path in a resource path is not allowed and will raise exceptions in a future release.\n",
      "  config_file = pkg_resources.resource_filename('ev2gym', config_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating directory: ./results/test\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "from stable_baselines3 import PPO, TD3, DDPG\n",
    "from sb3_contrib import TRPO\n",
    "import pkg_resources\n",
    "import os\n",
    "\n",
    "from ev2gym.models.ev2gym_env import EV2Gym\n",
    "from ev2gym.rl_agent.reward import profit_maximization\n",
    "from ev2gym.rl_agent.state import arrival_prices_flex\n",
    "from ev2gym.rl_agent.state import arrival_prices\n",
    "from ev2gym.baselines.heuristics import ChargeAsFastAsPossible\n",
    "from ev2gym.utilities.evaluators import evaluate_model\n",
    "\n",
    "# Select the configuration file\n",
    "config_file = \"/example_config_files/testPST.yaml\"\n",
    "config_file = pkg_resources.resource_filename('ev2gym', config_file)\n",
    "\n",
    "# Creating the environment\n",
    "env = EV2Gym(config_file,\n",
    "             render_mode=False,\n",
    "             save_plots=True,\n",
    "             save_replay=True,\n",
    "             save_mat=True,\n",
    "             overwrite_name='test',\n",
    "             state_function=arrival_prices_flex,\n",
    "             reward_function=profit_maximization,\n",
    "             flex_multiplier=0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e643aad-8787-4926-ad18-0d8f7ed1286d",
   "metadata": {},
   "source": [
    "### Generate the trajectory using the first agent (do not run if you dont want new trajectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ebb81c-af29-4c2a-82a2-884438497e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = ChargeAsFastAsPossible()\n",
    "while True:\n",
    "    action=agent.get_action(env)\n",
    "    obs, reward, done, a,info = env.step(action)\n",
    "\n",
    "    if done:\n",
    "        obs = env.reset()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee76e7cd-403c-4933-b81f-fe0a4246cfbc",
   "metadata": {},
   "source": [
    "## Now declare a new env and run the simulations\n",
    "Here you need to declare the variables that the enviroment is going to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d531019b-d81a-45ec-925b-91fcf1ff5553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder containing the models\n",
    "models_folder=\"./models/flex_00\"\n",
    "\n",
    "# State and reward (first is more important)\n",
    "our_state=arrival_prices\n",
    "our_reward=profit_maximization\n",
    "\n",
    "# Flex multiplier\n",
    "c=0.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d432d4be-e3c9-4a1c-a183-b2f6550afcac",
   "metadata": {},
   "source": [
    "### DDPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60885be9-da25-4341-8a31-d6c806fe14f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating directory: ./results/DDPG\n"
     ]
    }
   ],
   "source": [
    "env_rep = EV2Gym(config_file,\n",
    "             load_from_replay_path='./replay/replay_test.pkl',\n",
    "             render_mode=False,\n",
    "             save_plots=True,\n",
    "             save_replay=False,\n",
    "             save_mat=True,\n",
    "             overwrite_name='DDPG',\n",
    "             state_function=our_state,\n",
    "             reward_function=our_reward,\n",
    "             flex_multiplier=c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed007b58-64ec-48fc-980c-fadf4a2209e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting simulation data at ./results/DDPG/\n",
      "=====================================================\n",
      "total_ev_served:  46.0\n",
      "total_profits:  -221.20196355207077\n",
      "real_profits (no flexibility):  -221.20196355207077\n",
      "Up_flexibility (kWh):  2026.177153234585\n",
      "Down_flexibility (kWh):  955.7677050975296\n",
      "total_energy_charged:  1032.389263413058\n",
      "average_user_satisfaction:  0.9421122222222222\n",
      "energy_user_satisfaction:  -10000000.0\n",
      "reward:  -250.652946\n"
     ]
    }
   ],
   "source": [
    "run_dir = models_folder+\"/DDPG/\"\n",
    "model = DDPG.load(run_dir+\"best_model.zip\")\n",
    "model.set_env(env_rep)\n",
    "evaluate_model(model,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb739a1e-88bc-474c-9e62-c88d293b55cd",
   "metadata": {},
   "source": [
    "### PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6454dc4-20c1-47ae-86b0-a3e1ee19360a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating directory: ./results/PPO\n"
     ]
    }
   ],
   "source": [
    "env_rep = EV2Gym(config_file,\n",
    "             load_from_replay_path='./replay/replay_test.pkl',\n",
    "             render_mode=False,\n",
    "             save_plots=True,\n",
    "             save_replay=False,\n",
    "             save_mat=True,\n",
    "             overwrite_name='PPO',\n",
    "             state_function=our_state,\n",
    "             reward_function=our_reward,\n",
    "             flex_multiplier=c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "812f3398-a7d9-4978-8aeb-42ade6dff450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting simulation data at ./results/PPO/\n",
      "=====================================================\n",
      "total_ev_served:  46.0\n",
      "total_profits:  -217.62275464702319\n",
      "real_profits (no flexibility):  -217.62275464702324\n",
      "Up_flexibility (kWh):  2310.4979199406807\n",
      "Down_flexibility (kWh):  957.7433898771856\n",
      "total_energy_charged:  1039.411722706301\n",
      "average_user_satisfaction:  0.9517911111111113\n",
      "energy_user_satisfaction:  -10000000.0\n",
      "reward:  -269.752139\n"
     ]
    }
   ],
   "source": [
    "run_dir=models_folder+\"/PPO/\"\n",
    "model = PPO.load(run_dir+\"best_model.zip\")\n",
    "model.set_env(env_rep)\n",
    "evaluate_model(model,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645f3fc8-5244-4aaf-a5a7-c5f6468303b1",
   "metadata": {},
   "source": [
    "### TRPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "430ff89e-188b-49d0-9583-27792772ffc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating directory: ./results/TRPO\n"
     ]
    }
   ],
   "source": [
    "env_rep = EV2Gym(config_file,\n",
    "             load_from_replay_path='./replay/replay_test.pkl',\n",
    "             render_mode=False,\n",
    "             save_plots=True,\n",
    "             save_replay=False,\n",
    "             save_mat=True,\n",
    "             overwrite_name='TRPO',\n",
    "             state_function=our_state,\n",
    "             reward_function=our_reward,\n",
    "             flex_multiplier=c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78751474-4760-47f0-a21a-6686f554e366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting simulation data at ./results/TRPO/\n",
      "=====================================================\n",
      "total_ev_served:  46.0\n",
      "total_profits:  -173.12676447376012\n",
      "real_profits (no flexibility):  -173.12676447376\n",
      "Up_flexibility (kWh):  2842.9689485184763\n",
      "Down_flexibility (kWh):  741.3138986537906\n",
      "total_energy_charged:  811.9861584854725\n",
      "average_user_satisfaction:  0.8457115198969695\n",
      "energy_user_satisfaction:  -10000000.0\n",
      "reward:  -523.530841\n"
     ]
    }
   ],
   "source": [
    "run_dir=models_folder+\"/TRPO/\"\n",
    "model = TRPO.load(run_dir+\"best_model.zip\")\n",
    "model.set_env(env_rep)\n",
    "evaluate_model(model,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf22f2b-71b4-48d1-9599-f189ff5f3e87",
   "metadata": {},
   "source": [
    "### TD3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5fe3f4c8-b270-4034-9023-bed6b4ee1155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating directory: ./results/TD3\n"
     ]
    }
   ],
   "source": [
    "env_rep = EV2Gym(config_file,\n",
    "             load_from_replay_path='./replay/replay_test.pkl',\n",
    "             render_mode=False,\n",
    "             save_plots=True,\n",
    "             save_replay=False,\n",
    "             save_mat=True,\n",
    "             overwrite_name='TD3',\n",
    "             state_function=our_state,\n",
    "             reward_function=our_reward,\n",
    "             flex_multiplier=c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d2a28fa-ea29-4f92-bd32-322277b83e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting simulation data at ./results/TD3/\n",
      "=====================================================\n",
      "total_ev_served:  46.0\n",
      "total_profits:  -225.34958733820187\n",
      "real_profits (no flexibility):  -225.34958733820199\n",
      "Up_flexibility (kWh):  1660.1115079776457\n",
      "Down_flexibility (kWh):  998.3555415329049\n",
      "total_energy_charged:  1068.0242904451716\n",
      "average_user_satisfaction:  0.9599677777777778\n",
      "energy_user_satisfaction:  -10000000.0\n",
      "reward:  -234.923165\n"
     ]
    }
   ],
   "source": [
    "run_dir=models_folder+\"/TD3/\"\n",
    "model = TD3.load(run_dir+\"best_model.zip\")\n",
    "model.set_env(env_rep)\n",
    "evaluate_model(model,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09b6085-8f7b-47de-9b43-b820caf7298d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EVthesis",
   "language": "python",
   "name": "evth"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
