{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31970b21-beaf-4d3f-961d-0d03881b22df",
   "metadata": {},
   "source": [
    "## Script to generate graphs from agents\n",
    "\n",
    "This script first runs one episode using ChargeAsFastAsPossible agent and saves the replay, then the other agents use the same trayectory. \n",
    "\n",
    "### First, declare the env and set the names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e3eb9e32-6374-48a8-82c0-b0ba71dc2aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12331/3305912387.py:15: DeprecationWarning: Use of .. or absolute path in a resource path is not allowed and will raise exceptions in a future release.\n",
      "  config_file = pkg_resources.resource_filename('ev2gym', config_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating directory: ./results/test_10\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "from stable_baselines3 import PPO, TD3, DDPG\n",
    "from sb3_contrib import TRPO\n",
    "import pkg_resources\n",
    "import os\n",
    "\n",
    "from ev2gym.models.ev2gym_env import EV2Gym\n",
    "from ev2gym.rl_agent.reward import profit_maximization\n",
    "from ev2gym.rl_agent.state import arrival_prices_flex\n",
    "from ev2gym.baselines.heuristics import ChargeAsFastAsPossible\n",
    "from ev2gym.utilities.evaluators import evaluate_model\n",
    "\n",
    "# Select the configuration file\n",
    "config_file = \"/example_config_files/testPST.yaml\"\n",
    "config_file = pkg_resources.resource_filename('ev2gym', config_file)\n",
    "\n",
    "# Creating the environment\n",
    "env = EV2Gym(config_file,\n",
    "             render_mode=False,\n",
    "             save_plots=True,\n",
    "             save_replay=True,\n",
    "             save_mat=True,\n",
    "             overwrite_name='test_10',\n",
    "             state_function=arrival_prices_flex,\n",
    "             reward_function=profit_maximization,\n",
    "             flex_multiplier=0.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e643aad-8787-4926-ad18-0d8f7ed1286d",
   "metadata": {},
   "source": [
    "### Generate the trajectory using the first agent (do not run if you dont want new trajectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b0ebb81c-af29-4c2a-82a2-884438497e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving replay file at ./replay/replay_test_10.pkl\n",
      "Plotting simulation data at ./results/test_10/\n"
     ]
    }
   ],
   "source": [
    "agent = ChargeAsFastAsPossible()\n",
    "while True:\n",
    "    action=agent.get_action(env)\n",
    "    obs, reward, done, a,info = env.step(action)\n",
    "\n",
    "    if done:\n",
    "        obs = env.reset()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee76e7cd-403c-4933-b81f-fe0a4246cfbc",
   "metadata": {},
   "source": [
    "## Now declare a new env and run the simulations\n",
    "Here you need to declare the variables that the enviroment is going to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d531019b-d81a-45ec-925b-91fcf1ff5553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder containing the models\n",
    "models_folder=\"./models/flex_10\"\n",
    "\n",
    "# State and reward (first is more important)\n",
    "our_state=arrival_prices_flex\n",
    "our_reward=profit_maximization\n",
    "\n",
    "# Flex multiplier\n",
    "c=1.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d432d4be-e3c9-4a1c-a183-b2f6550afcac",
   "metadata": {},
   "source": [
    "### DDPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60885be9-da25-4341-8a31-d6c806fe14f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating directory: ./results/DDPG\n"
     ]
    }
   ],
   "source": [
    "env_rep = EV2Gym(config_file,\n",
    "             load_from_replay_path='./replay/replay_test.pkl',\n",
    "             render_mode=False,\n",
    "             save_plots=True,\n",
    "             save_replay=False,\n",
    "             save_mat=True,\n",
    "             overwrite_name='DDPG',\n",
    "             state_function=our_state,\n",
    "             reward_function=our_reward,\n",
    "             flex_multiplier=c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed007b58-64ec-48fc-980c-fadf4a2209e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting simulation data at ./results/DDPG/\n",
      "=====================================================\n",
      "total_ev_served:  46.0\n",
      "total_profits:  600.780355072643\n",
      "real_profits (no flexibility):  -159.1318543431072\n",
      "Up_flexibility (kWh):  2882.5962093076264\n",
      "Down_flexibility (kWh):  709.1229093318032\n",
      "total_energy_charged:  774.3039202195303\n",
      "average_user_satisfaction:  0.8313675484899833\n",
      "energy_user_satisfaction:  -10000000.0\n",
      "reward:  153.495675\n"
     ]
    }
   ],
   "source": [
    "run_dir = models_folder+\"/DDPG/\"\n",
    "model = DDPG.load(run_dir+\"best_model.zip\")\n",
    "model.set_env(env_rep)\n",
    "evaluate_model(model,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb739a1e-88bc-474c-9e62-c88d293b55cd",
   "metadata": {},
   "source": [
    "### PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6454dc4-20c1-47ae-86b0-a3e1ee19360a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating directory: ./results/PPO\n"
     ]
    }
   ],
   "source": [
    "env_rep = EV2Gym(config_file,\n",
    "             load_from_replay_path='./replay/replay_test.pkl',\n",
    "             render_mode=False,\n",
    "             save_plots=True,\n",
    "             save_replay=False,\n",
    "             save_mat=True,\n",
    "             overwrite_name='PPO',\n",
    "             state_function=our_state,\n",
    "             reward_function=our_reward,\n",
    "             flex_multiplier=c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "812f3398-a7d9-4978-8aeb-42ade6dff450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting simulation data at ./results/PPO/\n",
      "=====================================================\n",
      "total_ev_served:  46.0\n",
      "total_profits:  700.7278578807246\n",
      "real_profits (no flexibility):  -169.2890960186345\n",
      "Up_flexibility (kWh):  3388.3409879104165\n",
      "Down_flexibility (kWh):  749.9440835654484\n",
      "total_energy_charged:  802.4016356680952\n",
      "average_user_satisfaction:  0.8545866666666666\n",
      "energy_user_satisfaction:  -10000000.0\n",
      "reward:  430.121394\n"
     ]
    }
   ],
   "source": [
    "run_dir=models_folder+\"/PPO/\"\n",
    "model = PPO.load(run_dir+\"best_model.zip\")\n",
    "model.set_env(env_rep)\n",
    "evaluate_model(model,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645f3fc8-5244-4aaf-a5a7-c5f6468303b1",
   "metadata": {},
   "source": [
    "### TRPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "430ff89e-188b-49d0-9583-27792772ffc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating directory: ./results/TRPO\n"
     ]
    }
   ],
   "source": [
    "env_rep = EV2Gym(config_file,\n",
    "             load_from_replay_path='./replay/replay_test.pkl',\n",
    "             render_mode=False,\n",
    "             save_plots=True,\n",
    "             save_replay=False,\n",
    "             save_mat=True,\n",
    "             overwrite_name='TRPO',\n",
    "             state_function=our_state,\n",
    "             reward_function=our_reward,\n",
    "             flex_multiplier=c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78751474-4760-47f0-a21a-6686f554e366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting simulation data at ./results/TRPO/\n",
      "=====================================================\n",
      "total_ev_served:  46.0\n",
      "total_profits:  708.0342373897674\n",
      "real_profits (no flexibility):  -166.63559156659625\n",
      "Up_flexibility (kWh):  3418.456726885701\n",
      "Down_flexibility (kWh):  734.7008875244887\n",
      "total_energy_charged:  810.2599503495453\n",
      "average_user_satisfaction:  0.855439866900315\n",
      "energy_user_satisfaction:  -10000000.0\n",
      "reward:  416.240366\n"
     ]
    }
   ],
   "source": [
    "run_dir=models_folder+\"/TRPO/\"\n",
    "model = TRPO.load(run_dir+\"best_model.zip\")\n",
    "model.set_env(env_rep)\n",
    "evaluate_model(model,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e5c5f4-3f2b-4502-bc43-04559b613487",
   "metadata": {},
   "source": [
    "### TD3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5099101c-791d-43a6-93d0-d090921c51c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating directory: ./results/TD3\n"
     ]
    }
   ],
   "source": [
    "env_rep = EV2Gym(config_file,\n",
    "             load_from_replay_path='./replay/replay_test.pkl',\n",
    "             render_mode=False,\n",
    "             save_plots=True,\n",
    "             save_replay=False,\n",
    "             save_mat=True,\n",
    "             overwrite_name='TD3',\n",
    "             state_function=our_state,\n",
    "             reward_function=our_reward,\n",
    "             flex_multiplier=c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "857f8ee0-e6c4-4283-acd2-901f7bd6e9a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting simulation data at ./results/TD3/\n",
      "=====================================================\n",
      "total_ev_served:  46.0\n",
      "total_profits:  501.59953410883344\n",
      "real_profits (no flexibility):  -210.11872046723994\n",
      "Up_flexibility (kWh):  2456.3134385147378\n",
      "Down_flexibility (kWh):  908.5994003762391\n",
      "total_energy_charged:  1017.5807027320333\n",
      "average_user_satisfaction:  0.9328855555555556\n",
      "energy_user_satisfaction:  -10000000.0\n",
      "reward:  456.121154\n"
     ]
    }
   ],
   "source": [
    "run_dir=models_folder+\"/TD3/\"\n",
    "model = TD3.load(run_dir+\"best_model.zip\")\n",
    "model.set_env(env_rep)\n",
    "evaluate_model(model,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9715b2fd-4dee-47a3-adef-a6a81590a066",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ec4e75-0d42-4296-9c67-6d67b547f08e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EVthesis",
   "language": "python",
   "name": "evth"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
